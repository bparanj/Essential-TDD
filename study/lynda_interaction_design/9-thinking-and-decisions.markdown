Defining Cognition

Cognition refers to a wide range of our mental processes, and what we would
often refer to as thinking.
It's a broad field, and includes many topics, including attention and memory,
reasoning and logic, and language.
Much of what is studied in the field of cognition is relevant to our work as
designers, because it helps us understand how we make sense and meaning of
the world around us,
solve problems, make decisions, and even communicate.
We've already discussed perception and attention, showing how color, motion, and
other characteristics can be used to direct or attract attention, and why they
can also be distracting.
Memory is a deep topic.
Psychologists study how we remember visual and verbal information, how long
we're able to remember it, what memory cues help us remember, and why we forget.
Memory is something we often take for granted.
We expect it to work for us, and we only notice it when it fails.
We increasingly depend upon our computers and smart phones to help us store
information, and make it available to us when we need it.
Our devices have become extensions of our own memory, so it's important that we
design interfaces that make it easy for people to enter, find, and retrieve
important information when they need it.
Language is another complex topic.
It's more than an interface being presented in English, Spanish, or Chinese.
Language is central to nearly all of our communication.
It makes it possible for us to transfer information from one person to another.
The words we choose influence what people understand, predict, and expect.
Written and verbal communication is at the center of nearly all social
interactions. When designing, we often need to craft interfaces that can adjust
to be displayed in different languages, but we also need to carefully choose the
labels and create content that will convey information accurately.
Not all of the information we remember and think about is in the form of words;
we also use mental imagery, or visualizations in our mind's eye.
We can see things in our mind, and think about them as objects, and even manipulate
them, such as rotating, changing the angle of view, or even changing color.
For example, imagine a capital letter D, rotated 90 degrees to the left, or
counterclockwise, and place the capital J centered just below it.
What do you see in your mind? An umbrella.
We can create completely new mental images of things we've never before seen or experienced.
Spaceships, and monsters, and the world's largest pizza, but we also have mental
images of things we've seen, and which are familiar.
Our memory for images is excellent; actually better than our memory for words.
Images can be used to represent information, to make it easier to understand, and
to make it easier to remember.
We don't just perceive and remember the world around us; we also strive to
understand it, and make sense of how it works.
Mental models are our thoughts and expectations about how things work in the
real world, and they influence how we behave, solve problems, perform tasks, and
they help us decide what to do.
Concept formation is closely related to mental models;
we take our specific experiences, break them down into meaningful pieces, and
sort them into general rules and groups.
For example, we have concepts about what a car is, how it works, and how to drive it.
We can get behind the wheel of almost any type of car, and successfully operate
it, even though we may have never driven that type of car before.
When we encounter a new situation, such as an electric car, we look for
similarities to our previous experiences, and we make decisions about how to
operate it based on our mental models.
The car has no gas engine, and may not even have a key for the ignition, but it
still has a steering wheel, accelerator, and brakes.
So with a little exploration, and experimentation, we're able to drive this new
type of car successfully too.
We should consider people's mental models and existing concepts when designing
new interfaces and devices to make it easier for them to understand it, use it,
and gain benefit from it.
An essential part of human cognition is our ability to identify patterns and
make connections or associations.
Each experience is not an isolated incident;
we continuously look for similarities that relate our current experiences to
our past experiences.
We are excellent at finding trends and patterns in the information around us,
and recognizing when we have seen a pattern or similar pattern before.
We even see patterns and attribute meaning when there may actually be none.
Associations are the connections between pieces of information, ideas, and experiences.
Meaning arises from the connections we make, and our understanding of something
gets better as the associations grow in number and strength.
Like patterns, we continuously look for these connections.
We build a library of memories, mental images, mental models, patterns, and the
connections between them through our entire life, and this is how we find
meaning, and understand the world around us.
And we use all of this for our powers of reasoning and logic.
We make decisions and solve problems based on what we know,
our understanding of the world, the connections among information and ideas, and
our expectations of what's likely to happen as a consequence of our actions.
Everything we've ever done, seen, heard, experienced, learned, and even
imagined, contributes to our future behavior; what will we do next?
So we're not just designing for the specific moment of interaction; we need to
consider what information and experience people bring with them, their
understanding of their past experiences, and of their current situation, their
needs, and their expectations of what will happen.
When we design for this larger context, we can craft interfaces and experiences
that fit their concepts, match their mental models, and meet their needs.

Cognitive Biases

Unfortunately, cognition is not perfect, and we do not always arrive at the
correct meaning or understanding.
We actually have cognitive biases that affect our decision making and
problem solving, so we don't always choose the ideal outcome, or act in the optimal way.
A cognitive bias is a pattern of poor analysis and judgment.
They're innate; simply part of our mental processes, and the even when we know
they exist, they're difficult to avoid.
These biases may occur because we're using a good cognitive process, but at the
wrong time, or in the wrong situation.
There may be survival benefits to acting quickly, than to making certain we're correct.
There may be perceptual distortions, such as strong emotions that change how
we allocate attention,
and we may simply lack the time and ability to understand and act appropriately.
Just as there are many aspects to cognition, there are also many cognitive
biases, but we'll focus our discussion on only a few that are most relevant to
interaction design.
Some of the cognitive biases that are most relevant to our work include the
framing effect, which explains why the way information is presented
influences how we understand it, and the decisions we make. We'll talk more
about this effect later.
The isolation effect tells us that things which are unique or stand out from
others are more likely to be remembered, and may be considered more important.
The mere exposure effect explains our tendency to like things simply
because they are familiar.
There are dozens of cognitive biases and effects. Although we only have time
to mention a few here,
many are relevant to interaction design, and there are books and resources
available from which you can learn more if you're interested.
We can interfere with accurate cognition, and manipulate attention, memory,
understanding, and decision making.
We've already discussed how we can direct attention with color, how dark
patterns can maliciously mislead people, and influence them to make bad
decisions, and how ambiguous labels and content can lead to confusion and poor choices.
We should know about cognitive biases, not because we want to manipulate people,
but because we can identify situations where the biases may occur, and attempt to
create designs that minimize them.
If we know that people tend to fixate on a single piece of information, and that
more recent information is considered more important, then we should be able to
design interfaces that make it easier to make better decisions.
Although we can make connections between interaction design, and the many
facets of cognitive psychology, there are a few topics that are particularly
relevant to our work.
Let's start by focusing on representation of information, framing, mental models,
and the concept of cognitive load.

Communicating with Labels and Icons

With digital interfaces, we need to communicate efficiently, because we have a
limited amount of space available on the screen, so we need to carefully choose
labels, and icons, and where they're placed.
Labels include navigation links, button text, image captions, and headers, and subheaders.
They communicate factual information, reflect the classification of that
information, and reveal the organization of the Web application.
Images and icons resemble, or portray the information and functionality they represent.
We rely on our memory, language, pattern recognition, and associations to
understand what we see and perceive.
The navigation on a Web site is often hierarchical, and how the links and labels
are presented influence how we understand that hierarchy.
Two common techniques for representing this structure are indenting, and grouping.
Grouping related items, and simply indenting them visually communicates the hierarchy.
Labels and links that are indented below another are perceived as subordinate to it.
The text labels we use for the navigation, links, and on tabs and buttons
should be meaningful and unambiguous, and we should use active, direct
verbs when possible.
They should help people accurately predict what will happen, or where they will
go, if they were to click or tap on it.
For example, OK and Cancel are notoriously ambiguous.
So use labels that directly correspond to what people are accepting or
rejecting, such as yes, cancel my account, and no, I want to keep my account.
The labels should also be consistent throughout the site or application.
Do not change the labels from page to page when they go to the same place, or
perform the same function, because when labels change, people think that the link
or function has changed.
One of the challenges when creating a navigation system is choosing
categories with minimal overlap, and then assigning clear, unambiguous, and predictive labels.
If people cannot determine which section of a Web site contains the information
they seek, then there is likely to be a problem with either the underlying
categories, such as too much overlap in the content, because they're not exclusive,
or there's a problem with the labels; ambiguous or vague labels that make it
difficult to predict where information may be found.
Not all navigation relies on text labels;
we also use small images, called thumbnails, and icons as links to content and functionality.
Like text labels, icons and images need to be recognizable, and meaningful.
One way to help people learn what icons represent is to use labels and tool
tips in conjunction with them.
Some Web applications give people the choice of displaying labels and tool tips.
This is helpful for novices who are learning the tool, but expert users no longer
need that assistance, and may be able to focus, and work more effectively, by
turning off the labels and tool tips.
While images are often photographs, or detailed illustrations, tend to be larger,
icons tend to be smaller and more symbolic.
Icons need to be identifiable, and unambiguously represent their content or function.
Icons are metaphors;
the image represents the information or action.
Some icons are easily understood, because they correspond directly to what we
know, and have experienced.
For example, roadway signs visually warn us of falling rocks, slippery surfaces,
and twisty corners, but some icons have learned associations, because they are
abstract, arbitrary, or have lost their association with real experiences.
For example, biohazard and radioactive symbols are abstract and arbitrary.
We must actively learn what they mean, and make the association between the
symbol, and what it represents.
The Save icon in many software tools still looks like a floppy disk, even though
floppy disks have mostly disappeared, and we increasingly rely on saving
information to the cloud.
This icon has lost its connection to the real world for many people, and so it
must be learned as if it were a more abstract symbol.
When an icon is abstract or arbitrary, it's important to use labels, and provide
context to facilitate understanding, and set the correct expectations.
Text labels for icons also need to be clear and unambiguous to avoid any
confusion, misunderstanding, and incorrect choices or decisions.
So, like text labels, images and icons are easiest to learn when they're
meaningful and recognizable, and once they're learned, they provide a quick and
efficient way to access content and functionality.

Framing Choices

How information is presented influences how we process it, how we make meaning
of it, and how we use it to make decisions and solve problems.
This is called the framing effect, and it's one of the cognitive biases we
mentioned just a moment ago.
A famous example of the framing effect simulated how people on juries understand
and make decisions about testimony they hear in court.
Two groups of people were shown the same photo of a car accident, but given
different verbal descriptions.
The red car bumped into the blue car, versus the red car smashed into the blue car.
People came to different conclusions about the severity and fault of the
accident, based on the description they heard.
The words bumped and smashed were used to frame the same photo in two
very different ways, which led people to think about, and remember the
photos differently.
People who heard bumped described the accident as minor, but people who heard
smashed described the accident as severe.
Remember, they saw the same photo, and all other details were identical.
One word changed how they thought about, and remembered the accident.
The way we label things, the location and placement of content and
functionality, and the images and information we include, all influence how
people understand it, and the choices they make.
Edward Tufte famously explained how the data and charts about the temperature
and the safety of the fuel systems of the space shuttle Challenger were
presented in a way that lead expert rocket scientists to make the wrong decision,
and launch when they should not have.
Although, most Web sites and mobile applications are not as mission critical as
an interface for NASA, we still need to ensure that information and
functionality are presented in ways that do not result in misunderstanding, and
incorrect expectations or predictions.
Clear, unambiguous labels, active verbs, and information in logical groups all
enhance understanding, and improve decision making, but framing effects involve
more than just labels.
They occur from the combination of the situation, information, and the choices available.
These effects are not simple, and they don't depend on a single design element, so
they can be hard to detect.
For example, if I've logged in to my brokerage to check on my retirement
account, and I see that the stock market is down that day, that one of my
mutual funds lost value, and the first action I see is to sell that fund, I may
be more likely to sell it.
If I don't see or realize that the stock market is only down slightly for the
day, but is up for the year, and that my mutual fund has still gained value
overall, then I may act based on what I see.
My decision to sell is framed by the negative information about losses, and
seeing the option to sell.
This choice makes sense given the context and content.
However, I may make a different decision if I had been shown the market
trend over the time, the mutual fund value over the time, and if there were
multiple actions available.
We cannot always foresee when framing effects may occur, because context and
content change over time, and from person to person, but as long as we
remember that our understanding of information, and the decisions we make
are relative, then we can strive to design for more clarity, and more
objective meaning.

Mental Models

A mental model is a person's internal representation of external reality;
our understanding of how things work in the real world, and the
relationships among them.
We all have expectations based on our learning and experience, and we bring
these mental models with us to every situation, problem, and interaction.
Mental models have a structure that closely matches what they represent.
They help us make predictions about what will happen next, and they're simpler
than the real thing they represent, because they model the ordinary or typical
thing, not every possible variation.
You have in your mind a concept of a car, but it doesn't include detail about
every car you've ever seen.
This generic concept is a mental model.
People plan their actions and make decisions based on their mental models.
If their mental model closely matches the actual behavior of the device or
interface, then people make accurate predictions, and correct decisions, and
choose appropriate actions.
But mental models are only part of the story.
There are two other types of models we need to discuss.
The mental model is in the mind of the person using the interface or device, but
a conceptual model describes how the interface actually works.
As designers, our mental models can influence the design process, so the
conceptual model is a combination of design, and the technology of the device.
The system model is how the interface or device actually works on the inside.
For example, you have a mental model for how an address book works.
You enter names alphabetically, and write down addresses and telephone numbers.
If we design a digital address book, we could create an interface that allows
people to enter information, search it, sort it, and maybe even share copies of it.
Some of these actions could never be done with an old-fashioned paper address
book, but the conceptual model for the digital version allows it.
The system model describes the structure of the database, the search and sort
algorithms, and the protocols for transmitting and receiving information.
The system model should be invisible to the person.
We rarely need to know how something works on the inside in order to use it.
Most of us drive very effectively, yet we couldn't personally repair our car engines.
As designers, we need to know about the system model, but the end user does not.
Ideally, the conceptual model and the mental model should be very similar.
When they match, people are able to quickly and easily learn how to use an
interface or device.
However, sometimes there's a difference between the designer's conceptual model,
and the person's mental model.
This may be due to different experiences, or simply because the designer knows
more about the device or interface and the system model.
In other words, the act of designing a device or interface helps us better
understand it, which makes it seem easier and more obvious to us.
This is experience and insight that other people don't have, so the device or
interface seems more difficult, and less meaningful to them.
Since we make design assumptions and choices based on our own experiences and
understanding, it's important to test designs with other people.
Many of us have had the experience of observing people in usability or
prototype testing, and wanting to yell out, click on the big button right in front of you!
It's the only big button on the screen, and it even has a perfectly clear label on it!
Yet we watch people repeatedly look over it, and look right at it without acting.
It's not because the button is hard to see, but because the person has a
different mental model of how the process works,
what they should be doing at that moment, and even what the action should be called.
There are four main components to modeling interactions with devices and interfaces.
Our designs need to make certain that information is presented in a way that's
familiar and meaningful.
We need to understand where people expect to find information on the device or
interface, and we need to understand the sequence of events that will logically
take them through the experience, without causing confusion, and which will
produce the desired results.
For example, if we're designing an e-commerce site, people have mental models
about the cart, and the checkout process.
This example closely matches our mental model; we expect to see a shopping cart
or bag icon at the top of the page, and we expect to be able to start the
checkout process from there.
However, if we were to use an obscure icon, or unfamiliar label, omit important
information, or place the feature in an unexpected location, then we would
violate the mental model, slow people down, and cause confusion.
Once we start the checkout process, we expect to tell the store where to send
the items, and we expect to enter our payment information at the end, just
before sending our order.
If we ask for information in the wrong order, or ask for additional
information that is perceived as unnecessary, such as gender, and birthday,
then we violate the mental model.
As designers, we strive to create experiences that closely match people's mental models.
When a device or interface behaves the way people expect, it's easier
to understand and use.

Understanding Cognitive Load

Thinking is hard, and people seek ease, and minimal effort.
We need to craft designs that make it easier and simpler to understand
information, and complete their tasks.
We use the terms cognitive load, and cognitive friction when we're discussing how
much effort people have to put into understanding information, making decisions,
and solving problems.
Not all cognitive load is bad; sometimes people really do need to think hard
to understand something, and make good decisions, such as choosing a physician, or a college.
But when we unnecessarily increase the load, and slow people down when something
could be easier, then we've caused cognitive friction.
Cognitive load is the level of effort associated with thinking, reasoning, and remembering.
There's only so much information we can pay attention to, think about,
and remember at a time.
If we exceed a person's level of ability to process information, then some
information gets overlooked, forgotten, or misunderstood.
We have even coined the phrase information overload to describe those situations
when there's just too much to think about.
With this in mind, there are some things we can do to reduce cognitive load, by
carefully managing the demands on attention, memory, and thinking.
Attention is a limited resource.
We cannot pay attention to everything around us all the time.
We focus our attention on what we think is the most important, and we expend our
cognitive effort on that.
We get frustrated when something distracts us, because it steals our attention.
When there's too much information, when it's disorganized, or unstructured,
and when we cannot identify the priorities, or importance, then we have trouble focusing.
This slows us down, and makes it more likely we'll overlook or omit something,
make incorrect choices, or have incorrect expectations about the outcomes.
Our short-term, or working memory, which is the memory for what we are actively
thinking about at any given moment, also has a limited capacity.
The amount of information we can keep in our minds, and think about at once, is constrained.
Different studies have described these memory limits.
Some have identified the limits in terms of the number of pieces or chunks of information.
In 1956, George Miller concluded that we can keep about seven pieces of
information in short-term memory.
And in 2001, Nelson Cowan concluded that we can keep four chunks of information
in short-term memory.
Research by Alan Baddeley in 1992 concluded that working memory is limited to
the amount of information we can rehearse in about two seconds.
Despite the differences in research and theory, we need to acknowledge that our
short-term or working memory is limited,
and when we expect people to remember too much, we overload their memory, and
some information will be lost.
In order to make it easier for people to remember information, we need to
understand the difference between recall, and recognition.
Recall is what we traditionally think of when we describe memory.
We store information in memory, and retrieve it when necessary.
For example, what's your best friend's birthday? Who was your second grade teacher?
You were not just thinking about those things, so you have to dig into your
memory to find them.
If you were able to access that information, then you successfully recalled it.
Recognition is when we are asked to make a correct selection from a set of choices.
We don't need to dig deep into our memory to find the information; we simply
need to review some options, and decide which is best.
For example, given a list of addresses, you could identify those where you have
lived from those where you have not.
You don't need to recall all of your past addresses;
you only need to recognize them.
Recognition is cognitively easier than recall,
and luckily, many of our experiences with interfaces and devices involve
selecting from choices, rather than actively recalling information.
Still, we should design with memory limits in mind.
Show people information and functionality when they need it.
Don't make them remember it.
Put information and functionality where people expect to find it.
Don't hide it or make them go looking for it.
Present information in meaningful ways, using good labels, and good icons.
Don't make them stop and think, what does this mean?
There are also a few things we can do to reduce cognitive load with smart defaults.
Identify smart defaults based on context, usage patterns, and past behavior.
Present smart defaults when they're likely to be correct, and make default
choices easy to change when they're not.
In this example, I've done a search for pizza on Google, but it has detected my
location, and it automatically selects that, and it ranks the search results based
on my location, yet it's easy to change my location, in case it's wrong.
And it also understands that I'm likely to want a map to a location, and so it
predicts my needs, and it presents this information automatically.
This is very smart.
Cognitive friction slows us down.
It occurs when our thinking, reasoning, and memory encounter things that change
over time, location, or context.
When content and functionality change without purpose across a site or
application, it slows us down.
When content and functionality appear the same, and actually work differently, it slows us down.
If the interaction and meaning were consistent, we would not need to slow
down and think about it.
Common interactions would be easier to learn, and would be more efficient, if they
used the same mental models, and relied on the same design patterns.
For example, search filters do basically the same thing.
They narrow down a set of results, but they often work a little differently
on different sites.
So we experience some cognitive friction when we have to slow down, think about
it, and learn how to use the filters from site to site.
However, different contexts, different problems, and even different information
may require different interactions.
For example, buying a mutual fund is different than buying a pair of jeans.
Even though these are both purchasing activities, we recognize that they have
some differences, but we still expect the overall process to be similar.
Choose a product, pay for the product, receive the product.
We don't expect buying mutual funds to be just like buying jeans, so we're not
surprised by the differences.
However, there may be situations that appear similar on the surface, but have
differences we do not notice, and then we encounter cognitive friction.
We expect the interaction to happen one way, but when it differs, we need to
slow down, think, and take the time to understand why it was different.
For example, it may seem that paying bills online and making a bank transfer are
basically the same thing, moving money from one account to another.
But they're actually different processes, using different banking systems.
Our mental model tells us it's the same, but the system models are different, and
this can lead to different experiences that cause cognitive friction.
This is contrary to our expectations, because the tasks appear similar, but they're not.
There are a few things we can do to reduce cognitive friction;
understand people's mental models, then make certain their expectations are
aligned with the behavior and output of the interface; the conceptual model.
Provide meaningful information to explain context and outcomes.
Concise content, examples, and illustrations can help answer common questions.
Help keep people focused on the end goal of the interaction;
whether they're playing a game, listening to music, or working on a blog post,
be clear about how to keep moving forward to the next level, the next song, or
to the review and publish screen.
Look for opportunities to simplify the interaction, and reduce cognitive load.
Avoid presenting too much information at a time.
Ask for only the information necessary, and break large tasks into smaller,
more manageable steps.
Provide access to help and instructions for new and complex interactions.
Many applications on touch devices use instructional overlays the first time
the application is run.
This helps people understand where to touch, and what gestures to use;
something that would be very difficult to communicate with written instructions.
In this example, the Pulse newsreader shows a simple overlay the first time
it starts, and it tells you how to navigate and select stories to read, tap, and swipe.
And as soon as you begin interacting, the overlay goes away.
Thinking and memory require effort, but we can design devices and interfaces that
do much of the work for us.
By understanding what increases cognitive load, and what causes cognitive
friction, we can create conceptual models that match the mental models, and then
only ask people to do the work that's necessary.
